{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geographical Plotting\n",
    "\n",
    "### Instructor: Rossano Schifanella\n",
    "Email: [rossano.schifanella@unito.it](mailto:rossano.schifanella@unito.it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Modifiable Areal Unit Problem, visually, in Python\n",
    "\n",
    "> [Dani Arribas-Bel](http://darribas.org) ([@darribas](http://twitter.com/darribas))\n",
    "\n",
    "The [Modifiable Areal Unit Problem](https://en.wikipedia.org/wiki/Modifiable_areal_unit_problem) (MAUP) is a well know phenomenon for any researcher interested in spatial issues. In this notebook, we'll get our hands dirty experimenting with different geographical configurations and will see, in a practical way, some of the implications of the MAUP. In doing this, we'll also tour some of the basic functionality in [`geopandas`](http://geopandas.org). \n",
    "\n",
    "To motivate this exercise, let us start from the end and show how, the exact same underlying geography, can generate radically different maps, depending on how we aggregate it:\n",
    "\n",
    "![Comparison](figs/comparison.png)\n",
    "\n",
    "In this case, we have started from a set of points located in a hypothetical geography (left panel). We can think of them as firms located over a regional economy, the distribution of a particular species of trees over space, or any other phenomenon where the main unit of observation can be described as points located somewhere in space. Now, in the central pane, we have overlayed a five by five grid and, for every polygon, which we could think of a regions, we have counted the number of units and assigned a color based on its value. In the right pane, we have done the same, using the same underlying distribution of points, but have overlaid a ten by ten grid of polygons.\n",
    "\n",
    "The gist of the MAUP is that, even though the original distribution is the same, the representation we access by looking at the aggregate can vary dramatically depending on the characteristics of this aggregation. In our example, the units were points and the aggregation were simple polygons in a grid. But the same problem occurs, for example, when we look at income over individuals and aggregate the average in neighborhoods, regions or countries: if the units we use for this aggregation are not meaningful, in other words, if they don't match well the underlying process, there can be substantial distortions.\n",
    "\n",
    "Now we have the conceptual idea clear, let's see how we have arrived to the picture above! Before anything, here are the libraries you'll need to run this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate polygon geographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need an engine that generates grids of different sides. This will allow us later to easily create many geographies with different characteristics, which will dictate the aggregation process. We can solve this problem with the following method, which generates polygons and collects them into a `GeoSeries`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridder(nr, nc):\n",
    "    '''\n",
    "    Return a grid with `nr` by `nc` polygons\n",
    "    ...\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    nr     : int\n",
    "             Number of rows\n",
    "    nc     : int\n",
    "             Number of columns\n",
    "    '''\n",
    "    x_breaks = np.linspace(0, 1, nc+1)\n",
    "    y_breaks = np.linspace(0, 1, nr+1)\n",
    "    polys = []\n",
    "    for x, y in product(range(nc), range(nr)):\n",
    "        poly = [(x_breaks[x], y_breaks[y]), \\\n",
    "                (x_breaks[x], y_breaks[y+1]), \\\n",
    "                (x_breaks[x+1], y_breaks[y+1]), \\\n",
    "                (x_breaks[x+1], y_breaks[y])]\n",
    "        polys.append(Polygon(poly))\n",
    "    return gpd.GeoSeries(polys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once defined, it's easy to generate a grid of, for example, four by three polygons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polys = gridder(3, 4)\n",
    "polys.plot(alpha=0.4, edgecolor='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate points within the geography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the \"engine\" to generate the geography, we need to create observations that we can pinpoint over space. The easiest way is to randomly generate points within the bounding box of the geographies we create, and store them in a different `GeoSeries`. That's exactly what the following function does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pts(n):\n",
    "    '''\n",
    "    Generate `n` points over space and return them as a GeoSeries\n",
    "    ...\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    n        : int\n",
    "               Number of points to generate\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    pts      : GeoSeries\n",
    "               Series with the generated points\n",
    "    '''\n",
    "    xy = pd.DataFrame(np.random.random((n, 2)), columns=['X', 'Y'])\n",
    "    pts = gpd.GeoSeries(xy.apply(Point, axis=1))\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to create, for example, 100 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed to always get the same locations\n",
    "np.random.seed(123)\n",
    "pts = gen_pts(100)\n",
    "pts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already have tools to create both the underlying points *and* a geography in which to aggregate it, let us imagine what this could look like. In fact, stop imagining and simply plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "polys.plot(alpha=0, ax=ax)\n",
    "pts.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate points to polygon\n",
    "\n",
    "Now, to get to a map like those above, we need a way to assign how many points are within each polygon. The following method does exactly that, albeit in a fairly computationally expensive way. There are faster ways to do it in `geopandas` ([spatial join](https://github.com/geopandas/geopandas/blob/master/examples/spatial_joins.ipynb), I'm looking at you), but they require additional dependencies, and are not as intuitive as this one I think. For now, this approach will have to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_pt2poly(pts, polys):\n",
    "    '''\n",
    "    Join points to the polygon where they fall into\n",
    "    \n",
    "    NOTE: computationally inefficient, so slow on large sizes\n",
    "    ...\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    pts    : GeoSeries\n",
    "             Series with the points\n",
    "    polys  : GeoSeries\n",
    "             Series with the polygons\n",
    "    Returns\n",
    "    -------\n",
    "    mapa   : Series\n",
    "             Indexed series where the index is the point ID and the value is \n",
    "             the polygon ID.\n",
    "    '''\n",
    "    mapa = []\n",
    "    for i, pt in pts.iteritems():\n",
    "        for j, poly in polys.iteritems():\n",
    "            if poly.contains(pt):\n",
    "                mapa.append((i, j))\n",
    "                pass\n",
    "    mapa = np.array(mapa)\n",
    "    mapa = pd.Series(mapa[:, 1], index=mapa[:, 0])\n",
    "    return mapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how we can collect the count for each polygon in a `GeoDataFrame` that also holds their geometries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt2poly = map_pt2poly(pts, polys)\n",
    "count = pt2poly.groupby(pt2poly).size()\n",
    "db = gpd.GeoDataFrame({'geometry': polys, 'count': count})\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have everything we need to make a map of the counts of points per polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.plot(column='count', scheme='quantiles', legend=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated\n",
    "\n",
    "Although we have all the pieces, one of the beauties of scripting languages like Python is that they allow you wrap different functionality so that obtaining the final outcome is easier than repeating every step every time you need the final product. In this case, we can ease the process by encapsulating the process above into a single method that takes `nr`, `nc` and the points we want to plot and generate a table of counts per polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_table(nr, nc, pts):\n",
    "    '''\n",
    "    Create a table with counts of points in `pts` assigned to a geography of\n",
    "    `nr` rows and `nc` columns\n",
    "    ...\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    nr     : int\n",
    "             Number of rows\n",
    "    nc     : int\n",
    "             Number of columns\n",
    "    pts    : GeoSeries\n",
    "             Series with the generated points\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tab    : GeoDataFrame\n",
    "             Table with the geometries of the polygons and the count of \n",
    "             points that fall into each of them\n",
    "    '''\n",
    "    polys = gridder(nr, nc)\n",
    "    walk = map_pt2poly(pts, polys)\n",
    "    count = walk.groupby(walk).size().reindex(polys.index).fillna(0)\n",
    "    tab = gpd.GeoDataFrame({'geometry': polys, 'count': count})\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can generate the counts for a five by five grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_5x5 = count_table(5, 5, pts)\n",
    "counts_5x5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And quickly plot it on quantile map using `PySAL` under the hood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_5x5.plot(column='count', scheme='quantiles', k =4, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further MAUP exploration\n",
    "\n",
    "Now we have all the pieces we require in an accessible way, let's explore what the choropleth looks like for the same set of points when we aggregate them into different geographies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.random.seed(123)\n",
    "pts = gen_pts(1000)\n",
    "sizes = [5, 10]\n",
    "f, axs = plt.subplots(1, len(sizes)+1, figsize=(9*len(sizes), 6))\n",
    "pts.plot(ax=axs[0])\n",
    "axs[0].set_title('Original point pattern')\n",
    "for size, ax in zip(sizes, axs[1:]):\n",
    "    tab = count_table(size, size, pts)\n",
    "    tab.plot(column='count', scheme='quantiles', \\\n",
    "             cmap='Blues', ax=ax, linewidth=0)\n",
    "    ax.set_title(\"%i by %i grid\"%(size, size))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate a plot for each case in which we compare the points, with the geography, with the final map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_case(nr, nc, pts):\n",
    "    '''\n",
    "    Generate an image with the original distribution, the geography, and the resulting map\n",
    "    ...\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    nr     : int\n",
    "             Number of rows\n",
    "    nc     : int\n",
    "             Number of columns\n",
    "    pts    : GeoSeries\n",
    "             Series with the generated points\n",
    "    '''\n",
    "    tab = count_table(nr, nc, pts)\n",
    "    f, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    pts.plot(ax=axs[0])\n",
    "    tab.plot(alpha=0, ax=axs[1])\n",
    "    \n",
    "    tab.plot(column='count', scheme='quantiles', \\\n",
    "             cmap='Blues', ax=axs[2], linewidth=0)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case(7, 4, pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then run if for several cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "pts = gen_pts(500)\n",
    "plot_case(2, 2, pts)\n",
    "plot_case(5, 5, pts)\n",
    "plot_case(10, 10, pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">The Modifiable Areal Unit Problem, visually, in Python</span> by <a xmlns:cc=\"http://creativecommons.org/ns#\" href=\"http://darribas.org\" property=\"cc:attributionName\" rel=\"cc:attributionURL\">Dani Arribas-Bel</a> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
